{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import wandb\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from statistics import mean, stdev\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "\n",
    "from inverse_stable_diffusion import InversableStableDiffusionPipeline\n",
    "from diffusers import DPMSolverMultistepScheduler\n",
    "import open_clip\n",
    "from optim_utils import *\n",
    "from io_utils import *\n",
    "\n",
    "\n",
    "def save_intermediate_results(obj: torch.tensor, index_of_step: int, filenname: str, dirpath: str = \"OUT/intermediate_results\", suffix: str = '.png'):\n",
    "    \"\"\"\n",
    "    Save intermediate results of Tree-Ring watermarking\n",
    "    Though B should be 1 here, because somehow Tree-Ring throws errors for B > 1\n",
    "    \n",
    "    @param res: torch.tensor of shape (B, C, H, W)\n",
    "    \"\"\"\n",
    "    os.makedirs(dirpath, exist_ok=True)\n",
    "    obj = obj[0]  # (C, H, W)\n",
    "    for i in range(obj.shape[0]):\n",
    "        img = obj[i].detach().cpu().numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min()) * 255  # Normalize to 0-255\n",
    "        img = Image.fromarray(img.astype('uint8'), 'L')\n",
    "        img.save(os.path.join(dirpath, filenname.format(index_of_step) + f'_{i}' + suffix))  # e.g. 1___init_latents_no_w_0.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='diffusion watermark')\n",
    "parser.add_argument('--run_name', default='test')\n",
    "parser.add_argument('--dataset', default='Gustavosta/Stable-Diffusion-Prompts')\n",
    "parser.add_argument('--start', default=0, type=int)\n",
    "parser.add_argument('--end', default=10, type=int)\n",
    "parser.add_argument('--image_length', default=512, type=int)\n",
    "parser.add_argument('--model_id', default='stabilityai/stable-diffusion-2-1-base')\n",
    "parser.add_argument('--with_tracking', action='store_true')\n",
    "parser.add_argument('--num_images', default=1, type=int)\n",
    "parser.add_argument('--guidance_scale', default=7.5, type=float)\n",
    "parser.add_argument('--num_inference_steps', default=50, type=int)\n",
    "parser.add_argument('--test_num_inference_steps', default=None, type=int)\n",
    "parser.add_argument('--reference_model', default=None)\n",
    "parser.add_argument('--reference_model_pretrain', default=None)\n",
    "parser.add_argument('--max_num_log_image', default=100, type=int)\n",
    "parser.add_argument('--gen_seed', default=0, type=int)\n",
    "\n",
    "# watermark\n",
    "parser.add_argument('--w_seed', default=999999, type=int)\n",
    "parser.add_argument('--w_channel', default=0, type=int)\n",
    "parser.add_argument('--w_pattern', default='rand')\n",
    "parser.add_argument('--w_mask_shape', default='circle')\n",
    "parser.add_argument('--w_radius', default=10, type=int)\n",
    "parser.add_argument('--w_measurement', default='l1_complex')\n",
    "parser.add_argument('--w_injection', default='complex')\n",
    "parser.add_argument('--w_pattern_const', default=0, type=float)\n",
    "\n",
    "# for image distortion\n",
    "parser.add_argument('--r_degree', default=None, type=float)\n",
    "parser.add_argument('--jpeg_ratio', default=None, type=int)\n",
    "parser.add_argument('--crop_scale', default=None, type=float)\n",
    "parser.add_argument('--crop_ratio', default=None, type=float)\n",
    "parser.add_argument('--gaussian_blur_r', default=None, type=int)\n",
    "parser.add_argument('--gaussian_std', default=None, type=float)\n",
    "parser.add_argument('--brightness_factor', default=None, type=float)\n",
    "parser.add_argument('--rand_aug', default=0, type=int)\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "if args.test_num_inference_steps is None:\n",
    "    args.test_num_inference_steps = args.num_inference_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = None\n",
    "if args.with_tracking:\n",
    "    wandb.init(project='diffusion_watermark', name=args.run_name, tags=['tree_ring_watermark'])\n",
    "    wandb.config.update(args)\n",
    "    table = wandb.Table(columns=['gen_no_w', 'no_w_clip_score', 'gen_w', 'w_clip_score', 'prompt', 'no_w_metric', 'w_metric'])\n",
    "\n",
    "# load diffusion model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "scheduler = DPMSolverMultistepScheduler.from_pretrained(args.model_id, subfolder='scheduler')\n",
    "pipe = InversableStableDiffusionPipeline.from_pretrained(\n",
    "    args.model_id,\n",
    "    scheduler=scheduler,\n",
    "    #torch_dtype=torch.float16,\n",
    "    torch_dtype=torch.float32,\n",
    "    revision='fp16',\n",
    "    )\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "# reference model\n",
    "if args.reference_model is not None:\n",
    "    ref_model, _, ref_clip_preprocess = open_clip.create_model_and_transforms(args.reference_model, pretrained=args.reference_model_pretrain, device=device)\n",
    "    ref_tokenizer = open_clip.get_tokenizer(args.reference_model)\n",
    "\n",
    "# dataset\n",
    "dataset, prompt_key = get_dataset(args)\n",
    "\n",
    "tester_prompt = '' # assume at the detection time, the original prompt is unknown\n",
    "text_embeddings = pipe.get_text_embedding(tester_prompt)\n",
    "\n",
    "# ground-truth patch\n",
    "gt_patch = get_watermarking_pattern(pipe, args, device)\n",
    "\n",
    "results = []\n",
    "clip_scores = []\n",
    "clip_scores_w = []\n",
    "no_w_metrics = []\n",
    "w_metrics = []\n",
    "\n",
    "for i in tqdm(range(args.start, args.end)):\n",
    "    seed = i + args.gen_seed\n",
    "    \n",
    "    current_prompt = dataset[i][prompt_key]\n",
    "    \n",
    "    ### generation\n",
    "    # generation without watermarking\n",
    "    set_random_seed(seed)\n",
    "    init_latents_no_w = pipe.get_random_latents()\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    save_intermediate_results(init_latents_no_w, index_of_step=1, dirpath='OUT', filenname='{}___init_latents_no_w')\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    outputs_no_w = pipe(\n",
    "        current_prompt,\n",
    "        num_images_per_prompt=args.num_images,\n",
    "        guidance_scale=args.guidance_scale,\n",
    "        num_inference_steps=args.num_inference_steps,\n",
    "        height=args.image_length,\n",
    "        width=args.image_length,\n",
    "        latents=init_latents_no_w,\n",
    "        )\n",
    "    orig_image_no_w = outputs_no_w.images[0]\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    orig_image_no_w.save(\"OUT/2___orig_image_no_w.png\")\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # generation with watermarking\n",
    "    if init_latents_no_w is None:\n",
    "        set_random_seed(seed)\n",
    "        init_latents_w = pipe.get_random_latents()\n",
    "    else:\n",
    "        init_latents_w = copy.deepcopy(init_latents_no_w)\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    save_intermediate_results(init_latents_w, index_of_step=3, dirpath='OUT', filenname='{}___init_latents_w_BEFORE_RING')\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # get watermarking mask\n",
    "    watermarking_mask = get_watermarking_mask(init_latents_w, args, device)\n",
    "\n",
    "    # inject watermark\n",
    "    init_latents_w, init_latens_w_fft = inject_watermark(init_latents_w, watermarking_mask, gt_patch, args,\n",
    "                                                         # and-mill -------------------------------------------\n",
    "                                                         return_fft=True\n",
    "                                                         # and-mill -------------------------------------------\n",
    "                                                         )\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    save_intermediate_results(init_latents_w, index_of_step=4, dirpath='OUT', filenname='{}___init_latents_w_AFTER_RING')\n",
    "    #\n",
    "    save_intermediate_results(init_latens_w_fft, index_of_step=4, dirpath='OUT', filenname='{}___init_latents_w_AFTER_RING_FFT')\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    outputs_w = pipe(\n",
    "        current_prompt,\n",
    "        num_images_per_prompt=args.num_images,\n",
    "        guidance_scale=args.guidance_scale,\n",
    "        num_inference_steps=args.num_inference_steps,\n",
    "        height=args.image_length,\n",
    "        width=args.image_length,\n",
    "        latents=init_latents_w,\n",
    "        )\n",
    "    orig_image_w = outputs_w.images[0]\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    orig_image_w.save(\"OUT/5___orig_image_w.png\")\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    ### test watermark\n",
    "    # distortion\n",
    "    orig_image_no_w_auged, orig_image_w_auged = image_distortion(orig_image_no_w, orig_image_w, seed, args)\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    orig_image_no_w_auged.save(\"OUT/6___orig_image_no_w_auged.png\")\n",
    "    orig_image_w_auged.save(\"OUT/7___orig_image_w_auged.png\")\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # reverse img without watermarking\n",
    "    img_no_w = transform_img(orig_image_no_w_auged).unsqueeze(0).to(text_embeddings.dtype).to(device)\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    orig_image_no_w_auged.save(\"OUT/8___img_no_w.png\")\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    image_latents_no_w = pipe.get_image_latents(img_no_w, sample=False)\n",
    "\n",
    "    reversed_latents_no_w = pipe.forward_diffusion(\n",
    "        latents=image_latents_no_w,\n",
    "        text_embeddings=text_embeddings,\n",
    "        guidance_scale=1,\n",
    "        num_inference_steps=args.test_num_inference_steps,\n",
    "    )\n",
    "\n",
    "    # reverse img with watermarking\n",
    "    img_w = transform_img(orig_image_w_auged).unsqueeze(0).to(text_embeddings.dtype).to(device)\n",
    "    image_latents_w = pipe.get_image_latents(img_w, sample=False)\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    save_intermediate_results(image_latents_w, index_of_step=9, dirpath='OUT', filenname='{}___image_latents_w')\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    reversed_latents_w = pipe.forward_diffusion(\n",
    "        latents=image_latents_w,\n",
    "        text_embeddings=text_embeddings,\n",
    "        guidance_scale=1,\n",
    "        num_inference_steps=args.test_num_inference_steps,\n",
    "    )\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "    save_intermediate_results(reversed_latents_w, index_of_step=10, dirpath='OUT', filenname='{}___reversed_latents_w')\n",
    "    # and-mill -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # eval\n",
    "    no_w_metric, w_metric = eval_watermark(reversed_latents_no_w, reversed_latents_w, watermarking_mask, gt_patch, args)\n",
    "\n",
    "    if args.reference_model is not None:\n",
    "        sims = measure_similarity([orig_image_no_w, orig_image_w], current_prompt, ref_model, ref_clip_preprocess, ref_tokenizer, device)\n",
    "        w_no_sim = sims[0].item()\n",
    "        w_sim = sims[1].item()\n",
    "    else:\n",
    "        w_no_sim = 0\n",
    "        w_sim = 0\n",
    "\n",
    "    results.append({\n",
    "        'no_w_metric': no_w_metric, 'w_metric': w_metric, 'w_no_sim': w_no_sim, 'w_sim': w_sim,\n",
    "    })\n",
    "\n",
    "    no_w_metrics.append(-no_w_metric)\n",
    "    w_metrics.append(-w_metric)\n",
    "\n",
    "    if args.with_tracking:\n",
    "        if (args.reference_model is not None) and (i < args.max_num_log_image):\n",
    "            # log images when we use reference_model\n",
    "            table.add_data(wandb.Image(orig_image_no_w), w_no_sim, wandb.Image(orig_image_w), w_sim, current_prompt, no_w_metric, w_metric)\n",
    "        else:\n",
    "            table.add_data(None, w_no_sim, None, w_sim, current_prompt, no_w_metric, w_metric)\n",
    "\n",
    "        clip_scores.append(w_no_sim)\n",
    "        clip_scores_w.append(w_sim)\n",
    "\n",
    "# roc\n",
    "preds = no_w_metrics +  w_metrics\n",
    "t_labels = [0] * len(no_w_metrics) + [1] * len(w_metrics)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(t_labels, preds, pos_label=1)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "acc = np.max(1 - (fpr + (1 - tpr))/2)\n",
    "low = tpr[np.where(fpr<.01)[0][-1]]\n",
    "\n",
    "if args.with_tracking:\n",
    "    wandb.log({'Table': table})\n",
    "    wandb.log({'clip_score_mean': mean(clip_scores), 'clip_score_std': stdev(clip_scores),\n",
    "               'w_clip_score_mean': mean(clip_scores_w), 'w_clip_score_std': stdev(clip_scores_w),\n",
    "               'auc': auc, 'acc':acc, 'TPR@1%FPR': low})\n",
    "\n",
    "print(f'clip_score_mean: {mean(clip_scores)}')\n",
    "print(f'w_clip_score_mean: {mean(clip_scores_w)}')\n",
    "print(f'auc: {auc}, acc: {acc}, TPR@1%FPR: {low}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
